{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from si.linear_model import LogisticRegression\n",
    "from si.data.dataset import Dataset\n",
    "from si.metrics.accuracy import accuracy\n",
    "from si.emsemble.stacking_classifier import StackingClassifier\n",
    "from si.io.csv import read_csv\n",
    "\n",
    "# load the dataset\n",
    "from si.neighbors.knn_classifier import KNNClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5., 1., 1., ..., 1., 1., 1.],\n       [2., 1., 1., ..., 2., 1., 1.],\n       [2., 1., 1., ..., 3., 1., 1.],\n       ...,\n       [5., 2., 2., ..., 1., 1., 2.],\n       [2., 3., 2., ..., 3., 1., 1.],\n       [7., 6., 6., ..., 7., 1., 1.]])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(r\"C:\\Users\\maryg\\si\\datasets\\breast-bin.csv\")\n",
    "\n",
    "# split the dataset into features and labels\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# standardize the features\n",
    "X = StandardScaler().fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# create the model set\n",
    "knn1 = KNNClassifier()\n",
    "logistic_regression = LogisticRegression()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# create the final model\n",
    "knn2 = KNNClassifier(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# create the StackingClassifier\n",
    "model = StackingClassifier([knn1, logistic_regression], knn2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "KNNClassifier.fit() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[76], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# fit the model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\si\\src\\si\\emsemble\\stacking_classifier.py:29\u001B[0m, in \u001B[0;36mStackingClassifier.fit\u001B[1;34m(self, dataset, y)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# fit the models from the model set\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels:\n\u001B[1;32m---> 29\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# get predictions from each model\u001B[39;00m\n\u001B[0;32m     32\u001B[0m predictions \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[1;31mTypeError\u001B[0m: KNNClassifier.fit() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'X'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[77], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# evaluate the model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mscore\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\si\\src\\si\\emsemble\\stacking_classifier.py:68\u001B[0m, in \u001B[0;36mStackingClassifier.score\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscore\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: np\u001B[38;5;241m.\u001B[39mndarray, y: np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;124;03m    Returns the accuracy of the model.\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;124;03m    :return: Accuracy of the model.\u001B[39;00m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 68\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m     score \u001B[38;5;241m=\u001B[39m accuracy(y, y_pred)\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m score\n",
      "File \u001B[1;32m~\\si\\src\\si\\emsemble\\stacking_classifier.py:52\u001B[0m, in \u001B[0;36mStackingClassifier.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     50\u001B[0m predictions \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels:\n\u001B[1;32m---> 52\u001B[0m     model_predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m     predictions\u001B[38;5;241m.\u001B[39mappend(model_predictions)\n\u001B[0;32m     54\u001B[0m predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(predictions)\n",
      "File \u001B[1;32m~\\si\\src\\si\\neighbors\\knn_classifier.py:96\u001B[0m, in \u001B[0;36mKNNClassifier.predict\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset: Dataset) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;124;03m    It predicts the classes of the given dataset\u001B[39;00m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;124;03m        The predictions of the model\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mapply_along_axis(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_closest_label, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, arr\u001B[38;5;241m=\u001B[39m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX\u001B[49m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'X'"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"Accuracy: {score:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}